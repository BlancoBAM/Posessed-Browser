---
title: "AI Provider Setup"
description: "Connect Lilim, Ollama, Claude, OpenAI, Gemini, or any other AI provider to Posessed Browser"
---

# AI Provider Setup

Posessed Browser supports multiple AI providers. On [Lilith Linux](https://github.com/BlancoBAM/Lilith-Linux), **[Lilim](https://github.com/BlancoBAM/Lilim) is pre-configured** and requires no setup. On other systems, choose from the options below.

## Lilim (Default on Lilith Linux)

[Lilim](https://github.com/BlancoBAM/Lilim) is the intelligent local AI system built for Lilith Linux and Posessed Browser. It runs entirely on your machine — no API key, no cloud, no cost.

**On Lilith Linux:** Already configured. Open the browser and start using the Assistant.

**On other systems:** Install Lilim from [github.com/BlancoBAM/Lilim](https://github.com/BlancoBAM/Lilim), start the Lilim server, then set the API endpoint in Posessed Browser settings to `http://localhost:<lilim-port>`.

<Info>
  As Lilim evolves, Posessed Browser will automatically benefit — better
  reasoning, faster inference, and deeper integration with Lilith Linux system
  features are on the roadmap.
</Info>

---

## Ollama (Free, Local)

[Ollama](https://ollama.com) lets you run open-source LLMs locally for free.

1. Install Ollama from [ollama.com](https://ollama.com)
2. Pull a model: `ollama pull llama3` (or `mistral`, `gemma`, etc.)
3. In Posessed Browser: **Settings → AI Provider → Ollama**

**Best models for agent tasks:** `llama3`, `mistral-nemo`, `qwen2.5`

---

## LM Studio (Free, Local)

[LM Studio](https://lmstudio.ai) supports any GGUF model.

1. Download from [lmstudio.ai](https://lmstudio.ai)
2. Download any model from the in-app browser
3. Start the local server in LM Studio
4. In Posessed Browser: **Settings → AI Provider → LM Studio**

---

## Claude (Anthropic)

Best choice for complex agentic tasks and multi-step automation.

1. Get an API key from [console.anthropic.com](https://console.anthropic.com)
2. In Posessed Browser: **Settings → AI Provider → Claude**
3. Paste your API key

**Recommended models:**
| Model | Speed | Quality | Best for |
|-------|-------|---------|----------|
| Claude Opus | Slower | Best | Complex automation |
| Claude Sonnet | Medium | Great | General agent tasks |
| Claude Haiku | Fast | Good | Simple tasks |

---

## OpenAI

1. Get an API key from [platform.openai.com](https://platform.openai.com)
2. In Posessed Browser: **Settings → AI Provider → OpenAI**
3. Paste your API key

Supported models: `gpt-4o`, `o1`, `o1-mini`, `o3-mini`

---

## Gemini (Google)

1. Get an API key from [aistudio.google.com](https://aistudio.google.com)
2. In Posessed Browser: **Settings → AI Provider → Gemini**
3. Paste your API key

**Gemini Flash** is recommended for its speed and cost efficiency.

---

## Azure OpenAI / AWS Bedrock

For enterprise deployments:

- **Azure:** **Settings → AI Provider → Azure OpenAI** — enter your endpoint URL and API key
- **AWS Bedrock:** **Settings → AI Provider → AWS Bedrock** — enter your region and credentials

---

## OpenAI-Compatible Endpoints

Connect any API that follows the OpenAI spec (e.g., local servers, custom inference backends, or third-party compatible services):

**Settings → AI Provider → OpenAI-Compatible** → enter your base URL and API key.

---

## Which Model for Agent Tasks?

<Warning>
  Local LLMs (other than Lilim) may struggle with complex Agent Mode tasks.
  Lilim is purpose-built for the Posessed Browser environment. For other local
  models, we recommend testing before relying on them for automation.
</Warning>

For best results with Agent Mode:

1. **Lilim** (on Lilith Linux) — purpose-built, locally optimized
2. **Claude Opus/Sonnet** — strong reasoning, reliable tool use
3. **GPT-4o** — good all-rounder
4. **Gemini Flash** — fast, decent for simpler tasks
